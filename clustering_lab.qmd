---
title: "Lab 9: Clustering Ans"
subtitle: "Lab 9"
editor: visual
execute: 
  message: false
  warning: false
---

# Lab 9 - Clustering Ans

## Data

-   For this lab, we will reproduce the results of Reilly et al. (2023; Experiment 1). In Experiment 1, they were interested in whether clusters segregate by smell in a patient with anosmia (loss of smell). Do not worry about any of the statistical tests performed.

Reilly, J., Finley, A. M., Kelly, A., Zuckerman, B., & Flurie, M. (2021). Olfactory language and semantic processing in anosmia: A neuropsychological case control study. *Neurocase*, *27*(1), 86--96. <https://doi.org/10.1080/13554794.2020.1871491>

-   The data and analysis scripts can be found on OSF.

## Hierarchical clustering

-   Run a hierarchical cluster analysis as done in Reilly et al. (2021; Experiment 1). Please include both dendrograms. Do your dendrograms have similar pattern?

    -   We read in the data from OSF and tidy up the data.

    ```{r}

    library(tidyverse)
    library(osfr) # to read data directly from an OSF repo
    library(naniar) # to assess misingness
    library(dendextend) # for dendrograms
    library(patchwork) # for graph presentation
    library(factoextra) # for determining optimal clusters
    library(parameters) # for bootstrapped cluster analyses

    ```

## P01 Clustering

```{r}
        p01<-read_csv("https://osf.io/694mz/download")

        head(p01)

        p01 <- as.data.frame(p01)

        rownames(p01)<- p01$...1

        p01 <- p01[,-1]

        p01_dist <- dist(p01, method="euclidean")

        head(p01_dist)

```

```{r}

library(dendextend)
library(factoextra)


clust_p01 <- hclust(p01_dist, method="complete")

fviz_dend(clust_p01)

```

```         
    -   

    -   Tidy up the data from the OSF
```

```{r}
        # tidy table


        d <- read_csv("https://osf.io/zygvh/download")

        mturk<- d %>% group_by(Word, Dimension) %>% summarise(Rating=mean(Rating, na.rm = TRUE)) %>% pivot_wider(names_from = "Dimension", values_from = "Rating" )

        mturk <- as.data.frame(mturk)

        rownames(mturk)<- mturk[,1]

        # get rid of word col
        mturk <- mturk %>%
          select(-Word)

        mturk_dist <- dist(mturk, method = "euclidean")

```

```{r}

        library(dendextend)
        library(factoextra)

        clust_mturk <- hclust(mturk_dist)

        fviz_dend(clust_mturk, horiz=TRUE, repel = TRUE)

```

## Paper figures

````         
```{r}
# plot both dendrograms like Figure 3 in the article

# mturk dendrogram
d=fviz_dend(clust_mturk,k=5,horiz=TRUE, type="rectangle", cex=1, repel=TRUE, main="Turkers")

# p01 dendrogram
e=fviz_dend(clust_p01, k=3,  horiz = T, type = "rectangle", cex=1, main="P01")

d+e

```
````

## Different link method

```{r}
clust_mturk_ward = hclust(mturk_dist, method = "ward.D2")

clust_p01_ward = hclust(p01_dist, method = "ward.D2")

```

-   Using the Ward linkage method resulted in a small number of very minor differences between these analyses and those using the complete linkage method. In the round, it would appear that the findings are robust to different linkage methods.

## MTurk: Elbow, Silhouette, Gap

````         
```{r}
# Plot cluster results
p1 <- fviz_nbclust(mturk, FUN = hcut, method = "wss", 
                   k.max = 10) +
  ggtitle("(A) Elbow method")
p2 <- fviz_nbclust(mturk, FUN = hcut, method = "silhouette", 
                   k.max = 10) +
  ggtitle("(B) Silhouette method")

p3 <- fviz_nbclust(mturk, FUN = hcut, method = "gap_stat", 
                   k.max = 10, nboot=100) +
  ggtitle("(C) Gap statistic")

gridExtra::grid.arrange(p1, p2,p3,  nrow = 1)


```

-   There is relatively higher agreement between the elbow, silhouette, and gap methods when applied to the MTurk data. The elbow method suggests 2-3 clusters. The silhouette suggests 3, and the gap statistic suggests 2.

## P01: Elbow, Silhouette, Gap

```{r}
# Plot cluster results
p1 <- fviz_nbclust(p01, FUN = hcut, method = "wss", 
                   k.max = 10) +
  ggtitle("(A) Elbow method")
p2 <- fviz_nbclust(p01, FUN = hcut, method = "silhouette", 
                   k.max = 10) +
  ggtitle("(B) Silhouette method")

p3 <- fviz_nbclust(p01, FUN = hcut, method = "gap_stat", 
                   k.max = 10, nboot=100) +
  ggtitle("(C) Gap statistic")

gridExtra::grid.arrange(p1, p2,p3,  nrow = 1)


```

-   **The elbow, silhouette, and gap methods each suggest a different optimal number of clusters. The elbow method is difficult to interpret because the gradient is relatively steep and asymptotic. A conservative interpretation might take it to suggest that there are 4-5 clusters. The silhouette method suggests 2 and the gap statistic suggests 9.**

-   All together this suggests anywhere from 2-5 clusters for P01
````

## Reilly et al comparison

These results are not quite the same. Doing a HAC first, we get clusters ranging from 2-5 for P01 and 2-3 for MTurk sample. The study in question used 3 clusters for P01 and 5 clusters for MTurk. I assume Reilly et al. went with the number of clusters that made sense.

## Bootstrapping

## Mturk and P01

````         
::: callout-warning
This approach appears to identify too many clusters (small clusters). It is probably not a good idea to use this.
:::

```{r}
library(easystats)
#easystats
n <- n_clusters_hclust(mturk, standardize=FALSE, distance_method = "euclidian", hclust_method = "ward.D2",  iterations = 500)

plot(n)

n1 <- n_clusters_hclust(p01, standardize=FALSE, distance_method = "euclidian", hclust_method = "complete",  iterations = 500)

plot(n1)

```

-   The bootstrapped hierarchical clustering analyses suggested much larger cluster solutions for both the case study and the MTurk data. For the former, it recommended an 15-cluster solution. It recommended a 9-cluster solution for the MTurk data.

```{r}
#| fig-width: 6
#| fig-height: 12

fviz_dend(x = clust_mturk, cex = 0.8, lwd = 0.8, k = 2,
          rect = TRUE, 
          rect_border = "gray", horiz = TRUE, 
          rect_fill = FALSE)

fviz_dend(x = clust_p01, cex = .8, lwd = 0.8, k = 3,
          rect = TRUE, repel = TRUE, 
          rect_border = "gray",
          horiz = TRUE, 
          rect_fill = FALSE)

```

```         
```
````

-   Include a color-coded dendrogram for your final selection (use `dendextend`)

## K-means

-   Now perform a k-means cluster analysis. As a starting point, k = \# of clusters decided on above. \Plot a figure of the cluster solution.

    -   We can get the optimal number of clusters by running the `cluster_analysis` function from `easystats`. This is what I did.

        ```{r}

        cluster_analysis(mturk) # 4 clusters

        cluster_analysis(p01) # 3 clusters

        ```

    -   These results suggest the adequate number of clusters for P01 are 3 and Mturk are 4.

-   Use the consensus method `n_clusters` to determine the number of clusters. Include a figure of the new cluster solution.

    -   This returns same number of clusters as above with the `cluster_analysis` function.

        ```{r}
        n_clusters(p01) %>%
          plot()
        n_clusters(mturk) %>%
          plot()
        ```

        ```{r}

        cluster_analysis(mturk) %>% 
          plot()# 4 clusters

        cluster_analysis(p01) %>%
          plot()# 3 cluster
        ```

## Write-up

-   Write-up a report and make sure to interpret/name your clusters. If there are any differences between your analysis and theirs, describe them. Additionally, share your thoughts on how the authors shared their data.
